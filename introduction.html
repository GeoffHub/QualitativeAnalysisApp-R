<!DOCTYPE html>
<html lang="en">
    <meta http-equiv="content-type" content="text/html; charset=utf-8">
    
<h3> User Guide </h3>

    <p>This application has been developed to perform Qualitative analysis using R and Shiny. It comprises of the following sections, corresponding to the Phase Selection drop down list:
        <ol>
            <li>Importing a Corpus</li>
            <li>Pre-processing</li>
            <li>Feature Generation</li>
            <li>Feature Selection</li>
            <li>Initial Analysis</li>
            <li>Clustering Documents</li>
            <li>Clustering Words</li>
            <li>Words Network Generation</li>
        </ol>In what follows, all of the aforementioned sections will be briefly explained as regards their significance to the process of Qualitative analysis, and how options in each section could be used to analyse textual data.</p>
    <hr>
    
<h4> 1. Importing a Corpus </h4>
Users have two options for importing textual data:
    <dl>
<dt>Use Personal Corpus</dt>

        <dd>This option is chosen if a user seeks to upload her own text file (or a group of text files) as a corpus.</dd>
<dt>Sample Corpora</dt>

        <dd>This option is chosen if a user would like to analyse some readily available sample corpus. Presently, 3 corpora are available:
            <ul>
                <li><a href="http://www.expatforum.com/expats/uae-expat-forum-expats-living-uae/" target="_blank">UAE Expat Forum</a>: A corpus containing discussions from the UAE Expat discussion forum.</li>
                <li><a href="http://www.tripadvisor.co.uk/" target="_blank">UAE Trip Advisor</a>: A corpus containing discussions from the UAE Trip Advisor website.</li>
                <li><a href="http://www.politicalforum.com/middle-east/" target="_blank">Middle East Politics</a>: A corpus containin discussions about Middle Eastern Politics.</li>
            </ul>
        </dd>
    </dl>
    <hr>
    
<h4> 2. Pre-processing </h4>
This phase facilitates users in performing some basic pre-processing operations on textual data. These include the following:
    <ul>
        <li>Punctuation removal</li>
        <li>Numbers removal</li>
        <li>Stopwords removal</li>These are readily-available stopwords from the <a href="http://cran.r-project.org/package=tm" target="_blank">tm</a> package.
        <li>Custom Stopwords</li>Users may add their own stopwords, separated by a comma.
        <li>Custom Thesauri</li>Users may also add words and their replacements, separated by a comma. For example, a user may like to replace the word 'Bobby' with 'Police'.</ul>
    <hr>
    
<h4> 3. Feature Generation </h4>
After we have performed pre-processing operations on our corpus data, we must select weighting measures for words and documents. Once these have been chosen, a user may select any normalisation scheme too.
    <p>Several weighting measures are available in this application, due to their availability in the <a href="http://cran.r-project.org/package=tm" target="_blank">tm</a> package. These measures have been adopted from the <a href="http://en.wikipedia.org/wiki/SMART_Information_Retrieval_System" target="_blank">SMART Information Retrieval System</a>, and more information about the measures can be found by perusing the relevant research paper <a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.101.9086" target="_blank">here</a>.</p>
    <hr>
    
<h4> 4. Feature Selection </h4>
 <a href="http://en.wikipedia.org/wiki/Feature_selection" target="_bank">Feature Selection</a> is an important phase as it enables data analysts to reduce the number of features (in this case, words) by removing unnecessary ones. This technique is especially important in certain applications of Qualitative analysis, as with textual data it is normal to have an extremely large number of words.In this application, two basic methods are available:
    <ul>
        <li>Introduce a lower bound on frequency of words</li>
        <li>Remove words that increase data sparsity</li>
    </ul>
    <p>While there are other feature selection methods as well, such as the chi-squared test, they are best suited to Text Classification tasks rather than Exploratory tasks.</p>
    <p><em>Please Note: For this application, it is very important to reduce features in order to fit our data within memory limits.</em>

    </p>
    <hr>
    
<h4> 5. Initial Analysis </h4>
To enable basic analysis, two graphical plots are available in this section. These are the Rank-Frequency and Word-Frequency graphs.
    <p>The former plots words ordered in rank against log(frequency), to observe if our word distribution follows the <a href="http://en.wikipedia.org/wiki/Zipf's_law" target="_bank">Zipf's law</a>. The latter graph simply shows the frequency distribution of the most frequent words.</p>
    <hr>
    
<h4> 7. Clustering Documents </h4>
It can often be insightful to inspect how similar/dissimilar documents are based on words occurring in them. The intuition is that similar documents would have similar words, and this could be used to gain a rough idea about the number of topics being discussed in documents.
    <p>This application supports the projection of documents into a Euclidean space using <a href="http://en.wikipedia.org/wiki/Multidimensional_scaling" target="_bank">Multi-dimensional scaling</a>, after which the <a href="http://en.wikipedia.org/wiki/K-means_clustering" target="_bank">k-means</a> vector quantisation technique can be applied to group similar documents. Colours are assigned to documents depending on which group they belong to, and <a href="http://en.wikipedia.org/wiki/Topic_model" target="_bank">Topic modeling</a> is then performed to identify likely topics for each group of documents.</p>
    <p>To cluster documents and view possible topics for each group, we will have to first set the lower bound for word frequency. Once this is done, we select the number of document groups to identify from our corpus, and then the number of topics to identify from each of the document group. Clicking on the 'Generate Document Clusters' button will initiate the process of document cluster and topic identification.</p>
    <p><em>Depending on the size of users' datasets, some time may be required before a graph is printed to the screen.</em>

    </p>
    <hr>
    
<h4> 6. Clustering Words </h4>
This phase allows users to form clusters of words, both <a href="http://nlp.stanford.edu/IR-book/html/htmledition/flat-clustering-1.html" target="_blank">partitional</a> and <a href="http://nlp.stanford.edu/IR-book/html/htmledition/hierarchical-clustering-1.html" target="_blank">hierarchical</a>. For the former, a <a href="http://en.wikipedia.org/wiki/Tag_cloud" target="_blank">Word cloud</a> is presented as the final output, while for the latter, a <a href="http://en.wikipedia.org/wiki/Dendrogram" target="_blank">Dendrogram</a> is shown. A word cloud shows the frequency of a word (by varying the word's size in its representation) as well as its association to other words (by utilising the distance between words, where shorter distance means the words co-occur in documents). A dendrogram, on the other hand, shows the association of words more clearly by making use of a tree-like structure to collect co-occurring words in the same 'branches'.
    <p>To create a word cloud, we first select the 'Quantile for Word Frequency', which is actually used to set the lower bound for word frequencies. Then, we select the number of groups to identify using the <a href="http://en.wikipedia.org/wiki/K-means_clustering" target="_bank">k-means</a> technique. Finally, we select one of the two <a href="http://en.wikipedia.org/wiki/Force-directed_graph_drawing" target="_bank">graph-drawing algorithms</a>, and click on the generate button to plot the word cloud.</p>
    <p>To create a dendrogram, we select the lower word frequency bound to remove words occurring less than the selected number. Once this is done, we simply click on the generate button to plot the dendrogram. Currently, this application assumes that the method of calculating distances between our data is Euclidean, and that the clustering method is <a href="http://nlp.stanford.edu/IR-book/html/htmledition/group-average-agglomerative-clustering-1.html" target="_blank">Average-based clustering</a>.</p>
    <p><em>Depending on the size of users' datasets, some time may be required before an Associative Word Cloud or a Dendrogram are printed to the screen.</em>

    </p>
    <hr>
    
<h4> 8. Words Network Generation </h4>
This is the final functionality provided by the application, and basically provides users with a network of words. As when clustering words, users have to select the quantile for word frequency and the <a href="http://en.wikipedia.org/wiki/Force-directed_graph_drawing" target="_bank">graph-drawing algorithm</a> to finally print a words' network.
    <p><em>Since this technique is the most computationally expensive of all others available in this application, users are requested to be patient before the graph is printed.</em>

    </p>
